{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf051bca-a54f-4ff6-b657-08e38dfd34c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizer, BertConfig, BertModel\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03aa13e8-2b20-4700-9687-1a4954dc8860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faa18f7b-2fdf-4e06-b09a-9aa96aa76039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2994, 0.6470, 0.0536]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "image = Image.open('./data/data/' + str(1) + '.jpg')\n",
    "image = image.resize((224,224),Image.ANTIALIAS)\n",
    "image = np.asarray(image, dtype = 'float32')\n",
    "inputs = processor(text=[\"That is positive\", \"That is negative\", \"That is neutral\"], images=image, return_tensors=\"pt\", padding=True)\n",
    "outputs = model(**inputs)\n",
    "logits_per_image = outputs.logits_per_image # this is the image-text similarity score\n",
    "probs = logits_per_image.softmax(dim=1) # we can take the softmax to get the label probabilities\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9364289f-61d2-45ed-b048-df1ede85417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "descriptions = []\n",
    "emotions = []\n",
    "emotion_dic = {\"positive\":0, \"negative\":1, \"neutral\":2}\n",
    "e_dataframe = pd.read_csv(\"./data/train.txt\")\n",
    "pre_trained = 'bert-base-uncased'\n",
    "token = BertTokenizer.from_pretrained(pre_trained)\n",
    "\n",
    "for i in range(e_dataframe.shape[0]):\n",
    "    try:\n",
    "        idx = e_dataframe.iloc[i]['guid']\n",
    "        emotion = e_dataframe.iloc[i]['tag']\n",
    "        image = Image.open('./data/data/' + str(idx) + '.jpg')\n",
    "        with open('./data/data/' + str(idx) + '.txt', encoding='gbk') as fp:\n",
    "            description = fp.read()\n",
    "        images.append(image)\n",
    "        descriptions.append(description)\n",
    "        emotions.append(emotion_dic[emotion])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8840927c-e2a4-4f1b-9737-78ccf17dc3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_num = 0\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "for i in range(len(emotions)):\n",
    "    img = images[i]\n",
    "    inputs = processor(text=[\"That is positive\", \"That is negative\", \"That is neutral\"], images=img, return_tensors=\"pt\", padding=True).to(device)\n",
    "    outputs = model(**inputs)\n",
    "    logits_per_image = outputs.logits_per_image \n",
    "    probs = logits_per_image.softmax(dim=1) \n",
    "    correct_num += int(np.argmax(probs.tolist())==emotions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "535ff573-c457-4d01-9900-3e46d8ab66de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4216054013503376\n"
     ]
    }
   ],
   "source": [
    "print(correct_num/len(emotions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9c3c58c9-4b36-4c28-a3d6-bacaad046efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_num = 0\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "for i in range(len(emotions)):\n",
    "    img = images[i]\n",
    "    txt = descriptions[i][:35]\n",
    "    inputs = processor(text=[\"it's nice\", \"it's sad\", \"it's ok\"], images=img, return_tensors=\"pt\", padding=True).to(device)\n",
    "    outputs = model(**inputs)\n",
    "    logits_per_image = outputs.logits_per_image \n",
    "    probs = logits_per_image.softmax(dim=1) \n",
    "    correct_num += int(np.argmax(probs.tolist())==emotions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f93e45db-87a3-49de-a980-5e272c6ec2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5731432858214554\n"
     ]
    }
   ],
   "source": [
    "print(correct_num/len(emotions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acca4334-aa46-4a5b-a089-1df1c0157f31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
